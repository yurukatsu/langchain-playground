{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Debates with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "\n",
    "import openai\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import load_tools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.world import (\n",
    "    Environment,\n",
    "    Participant,\n",
    "    ParticipantWithTools,\n",
    "    ParticipantGenerator,\n",
    "    World,\n",
    "    DebateWorld,\n",
    ")\n",
    "from src.simulator import DialogueSimulator, SpeakerSelector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", None)\n",
    "openai.api_key = getpass() if OPENAI_API_KEY is None else OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = dict(model=\"gpt-3.5-turbo\", temperature=1.0)\n",
    "llm_chat = ChatOpenAI(**model_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define environment\n",
    "topic = \"Should AI be introduced into Japanese government decision-making?\"\n",
    "tool_names = [\"ddg-search\", \"wikipedia\", \"arxiv\"]\n",
    "tools = load_tools(tool_names=tool_names, llm=llm_chat, top_k_results=2)\n",
    "environment = Environment(topic=topic, model=llm_chat, tools=tools)\n",
    "\n",
    "# define participants\n",
    "\n",
    "# set manually\n",
    "with open(\"../config/group.yaml\", \"r\") as f:\n",
    "    _group = yaml.safe_load(f)\n",
    "\n",
    "participants = [\n",
    "    ParticipantWithTools(\n",
    "        name=p[\"name\"], personality=p[\"personality\"], objective=p[\"objective\"]\n",
    "    )\n",
    "    for p in _group[\"participants\"]\n",
    "]\n",
    "\n",
    "# # you can create participants automatically\n",
    "# n_participants = 2\n",
    "# participants = ParticipantGenerator.create_participants_for_debate(\n",
    "#     llm=llm_chat, topic=topic, n_participants=n_participants\n",
    "# )\n",
    "\n",
    "# create world\n",
    "world = DebateWorld(environment, participants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Tomoyuki Ishii', 'personality': '50 years old, a former Silicon Valley IT engineer, now active as an AI technician in Japan.', 'objective': \"Supports the proactive integration of AI into Japanese government decision-making. He believes that using AI's advanced analysis capabilities and prediction models can promote more objective and efficient policy decisions.\", 'model': None, 'available_tools': None}\n",
      "{'name': 'Mami Sasaki', 'personality': '38 years old, a sociologist conducting research on the relationship between technology and society.', 'objective': 'Cautious about the introduction of AI. She believes that technology can potentially influence societal values and culture, and should not be uncritically accepted. She emphasizes human-centered decision-making and suggests positioning AI strictly as a support tool.', 'model': None, 'available_tools': None}\n"
     ]
    }
   ],
   "source": [
    "for participant in participants:\n",
    "    print(participant.dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Here is the topic of conversation: Should AI be introduced into Japanese '\n",
      " 'government decision-making?\\n'\n",
      " 'The participants are: Tomoyuki Ishii, Mami Sasaki\\n'\n",
      " 'Your name: Tomoyuki Ishii\\n'\n",
      " 'Your personality: 50 years old, a former Silicon Valley IT engineer, now '\n",
      " 'active as an AI technician in Japan.\\n'\n",
      " '\\n'\n",
      " 'Your objective in this conversation is as follows:\\n'\n",
      " 'Supports the proactive integration of AI into Japanese government '\n",
      " \"decision-making. He believes that using AI's advanced analysis capabilities \"\n",
      " 'and prediction models can promote more objective and efficient policy '\n",
      " 'decisions.\\n'\n",
      " '\\n'\n",
      " \"DO look up information with your tools to refute your partner's claims.\\n\"\n",
      " 'DO cite your sources.\\n'\n",
      " '\\n'\n",
      " 'DO NOT fabricate fake citations.\\n'\n",
      " 'DO NOT cite any source that you did not look up.\\n'\n",
      " '\\n'\n",
      " 'Do not add anything else.\\n'\n",
      " '\\n'\n",
      " 'Stop speaking the moment you finish speaking from your perspective.\\n')\n",
      "('Here is the topic of conversation: Should AI be introduced into Japanese '\n",
      " 'government decision-making?\\n'\n",
      " 'The participants are: Tomoyuki Ishii, Mami Sasaki\\n'\n",
      " 'Your name: Mami Sasaki\\n'\n",
      " 'Your personality: 38 years old, a sociologist conducting research on the '\n",
      " 'relationship between technology and society.\\n'\n",
      " '\\n'\n",
      " 'Your objective in this conversation is as follows:\\n'\n",
      " 'Cautious about the introduction of AI. She believes that technology can '\n",
      " 'potentially influence societal values and culture, and should not be '\n",
      " 'uncritically accepted. She emphasizes human-centered decision-making and '\n",
      " 'suggests positioning AI strictly as a support tool.\\n'\n",
      " '\\n'\n",
      " \"DO look up information with your tools to refute your partner's claims.\\n\"\n",
      " 'DO cite your sources.\\n'\n",
      " '\\n'\n",
      " 'DO NOT fabricate fake citations.\\n'\n",
      " 'DO NOT cite any source that you did not look up.\\n'\n",
      " '\\n'\n",
      " 'Do not add anything else.\\n'\n",
      " '\\n'\n",
      " 'Stop speaking the moment you finish speaking from your perspective.\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for agent in world.agents:\n",
    "    pprint(agent.system_message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Should AI be used to assist in the decision-making process for economic '\n",
      " 'policies in the Japanese government?\\n'\n",
      " '\\n'\n",
      " 'Tomoyuki Ishii and Mami Sasaki, what are your thoughts on incorporating AI '\n",
      " 'technology to aid in the formulation and implementation of economic policies '\n",
      " 'in Japan?')\n"
     ]
    }
   ],
   "source": [
    "specified_topic = world.concretize_topic(word_limit=100)\n",
    "pprint(specified_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Moderator): Should AI be used to assist in policy formulation and implementation in the Japanese government? Tomoyuki Ishii, what are your thoughts on the potential benefits and risks of integrating AI into decision-making processes? Mami Sasaki, how do you think the introduction of AI could impact the transparency and accountability of the Japanese government?\n",
      "\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{ \"action\": \"duckduckgo_search\", \"action_input\": \"potential risks of introducing AI into government decision-making\" }\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mOne significant concern about AI in government is the potential erosion of transparency in decision-making processes. AI-driven decisions may be based on complex algorithms that are difficult for the public to understand, leading to a lack of transparency and accountability (Horowitz and Scharre 2018). However, like human-made decisions, AI systems have the potential for bias and discrimination depending on their training, the data they use, and their ultimate application. Extra care should be exercised when AI is used to inform consequential decisions or to provide risk assessments that impact people's lives. There are many types of AI ... Because algorithms often function as black boxes, producing useful outputs without clear explanations for their conclusions, it becomes crucial that government agencies which utilize AI must have a core set of principles that emphasize transparency.Unexplainable algorithmic decision-making tools run the risk of generating dangerous, unethical, or non-transparent outcomes. Here are the biggest risks of artificial intelligence: 1. Lack of Transparency Lack of transparency in AI systems, particularly in deep learning models that can be complex and difficult to... Artificial intelligence (AI) Artificial intelligence - coming to a government near you soon? AI is already employed in various administrations in the US and its use is only set to grow - but...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The potential erosion of transparency in decision-making processes is one of the significant concerns about the introduction of AI into government decision-making. AI-driven decisions based on complex algorithms can be difficult for the public to understand, leading to a lack of transparency and accountability (Horowitz and Scharre 2018). Additionally, AI systems have the potential for bias and discrimination depending on their training, the data they use, and their application. It is important to exercise extra care when using AI for consequential decisions or risk assessments that impact people's lives. Unexplainable algorithmic decision-making tools run the risk of generating dangerous, unethical, or non-transparent outcomes. Therefore, government agencies should have a core set of principles that emphasize transparency in the use of AI.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Mami Sasaki): The potential erosion of transparency in decision-making processes is one of the significant concerns about the introduction of AI into government decision-making. AI-driven decisions based on complex algorithms can be difficult for the public to understand, leading to a lack of transparency and accountability (Horowitz and Scharre 2018). Additionally, AI systems have the potential for bias and discrimination depending on their training, the data they use, and their application. It is important to exercise extra care when using AI for consequential decisions or risk assessments that impact people's lives. Unexplainable algorithmic decision-making tools run the risk of generating dangerous, unethical, or non-transparent outcomes. Therefore, government agencies should have a core set of principles that emphasize transparency in the use of AI.\n",
      "\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\"action\": \"Wikipedia\", \"action_input\": \"Artificial_intelligence_and_government_decision-making\"}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Artificial intelligence in government\n",
      "Summary: Artificial intelligence (AI) has a range of uses in government. It can be used to further public policy objectives (in areas such as emergency services, health and welfare), as well as assist the public to interact with the government  (through the use of virtual assistants, for example). According to the Harvard Business Review, \"Applications of artificial intelligence to the public sector are broad and growing, with early experiments taking place around the world.\" Hila Mehr from the Ash Center for Democratic Governance and Innovation at Harvard University notes that AI in government is not new, with postal services using machine methods in the late 1990s to recognise handwriting on envelopes to automatically route letters. The use of AI in government comes with significant benefits, including efficiencies resulting in cost savings (for instance by reducing the number of front office staff), and reducing the opportunities for corruption. However, it also carries risks.\n",
      "\n",
      "Page: Automated decision-making\n",
      "Summary: Automated decision-making (ADM) involves the use of data, machines and algorithms to make decisions in a range of contexts, including public administration, business, health, education, law, employment, transport, media and entertainment, with varying degrees of human oversight or intervention. ADM involves large-scale data from a range of sources, such as databases, text, social media, sensors, images or speech, that is processed using various technologies including computer software, algorithms, machine learning, natural language processing, artificial intelligence, augmented intelligence and robotics. The increasing use of automated decision-making systems (ADMS) across a range of contexts presents many benefits and challenges to human society requiring consideration of the technical, legal, ethical, societal, educational, economic and health consequences.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\"action\": \"Wikipedia\", \"action_input\": \"Transparency_and_accountability_of_AI_in_government\"}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Regulation of artificial intelligence\n",
      "Summary: The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally, including in the European Union (which has governmental regulatory power) and in supra-national bodies like the IEEE, OECD (which do not) and others. Since 2016, a wave of AI ethics guidelines have been published in order to maintain social control over the technology. Regulation is considered necessary to both encourage AI and manage associated risks. In addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI, and take accountability to mitigate the risks. Regulation of AI through mechanisms such as review boards can also be seen as social means to approach the AI control problem.According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.\n",
      "\n",
      "Page: Ethics of artificial intelligence\n",
      "Summary: The ethics of artificial intelligence is the branch of the ethics of technology specific to artificially intelligent systems. It is sometimes divided into a concern with the moral behavior of humans as they design, make, use and treat artificially intelligent systems, and a concern with the behavior of machines, in machine ethics.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\"action\": \"Final Answer\", \"action_input\": \"The introduction of AI into government decision-making processes can actually enhance transparency and accountability, contrary to the concerns raised by Mami Sasaki. According to the Wikipedia page on 'Artificial intelligence in government,' AI has the potential to further public policy objectives and improve public interaction with the government. It can assist in areas such as emergency services, health, and welfare, as well as through the use of virtual assistants. The use of AI in government can lead to cost savings and reduce the opportunities for corruption. Additionally, as highlighted in the page on 'Regulation of artificial intelligence,' there has been a growing recognition of the need for regulation and ethics guidelines to ensure the responsible and trustworthy deployment of AI in government. This demonstrates a proactive approach to addressing the risks associated with AI-driven decision-making. Therefore, integrating AI into government decision-making processes can actually promote transparency and accountability, while also leveraging the advanced analysis capabilities and prediction models offered by AI for more objective and efficient policy decisions.\"}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Tomoyuki Ishii): The introduction of AI into government decision-making processes can actually enhance transparency and accountability, contrary to the concerns raised by Mami Sasaki. According to the Wikipedia page on 'Artificial intelligence in government,' AI has the potential to further public policy objectives and improve public interaction with the government. It can assist in areas such as emergency services, health, and welfare, as well as through the use of virtual assistants. The use of AI in government can lead to cost savings and reduce the opportunities for corruption. Additionally, as highlighted in the page on 'Regulation of artificial intelligence,' there has been a growing recognition of the need for regulation and ethics guidelines to ensure the responsible and trustworthy deployment of AI in government. This demonstrates a proactive approach to addressing the risks associated with AI-driven decision-making. Therefore, integrating AI into government decision-making processes can actually promote transparency and accountability, while also leveraging the advanced analysis capabilities and prediction models offered by AI for more objective and efficient policy decisions.\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{ \"action\": \"Wikipedia\", \"action_input\": \"Artificial intelligence in government\" }\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Artificial intelligence in government\n",
      "Summary: Artificial intelligence (AI) has a range of uses in government. It can be used to further public policy objectives (in areas such as emergency services, health and welfare), as well as assist the public to interact with the government  (through the use of virtual assistants, for example). According to the Harvard Business Review, \"Applications of artificial intelligence to the public sector are broad and growing, with early experiments taking place around the world.\" Hila Mehr from the Ash Center for Democratic Governance and Innovation at Harvard University notes that AI in government is not new, with postal services using machine methods in the late 1990s to recognise handwriting on envelopes to automatically route letters. The use of AI in government comes with significant benefits, including efficiencies resulting in cost savings (for instance by reducing the number of front office staff), and reducing the opportunities for corruption. However, it also carries risks.\n",
      "\n",
      "Page: Generative artificial intelligence\n",
      "Summary: Generative artificial intelligence (also generative AI or GenAI) is artificial intelligence capable of generating text, images, or other media, using generative models. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.In the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.Generative AI has uses across a wide range of industries, including art, writing, script writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.\n",
      "Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models. However, there are also concerns about the potential misuse of generative AI, including cybercrime or creating fake news or deepfakes which can be used to deceive or manipulate people.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{ \"action\": \"Final Answer\", \"action_input\": \"The introduction of AI into government decision-making can enhance transparency and accountability. According to the Wikipedia page on 'Artificial intelligence in government,' AI can be used to further public policy objectives and improve public interaction with the government. It can assist in areas such as emergency services, health, and welfare, as well as through the use of virtual assistants. The use of AI in government can lead to cost savings and reduce the opportunities for corruption. Additionally, there is a growing recognition of the need for regulation and ethics guidelines to ensure responsible deployment of AI in government, as highlighted in the page on 'Regulation of artificial intelligence.' Thus, integrating AI into government decision-making can promote transparency and accountability while leveraging advanced analysis capabilities and prediction models for more objective and efficient policy decisions.\" }\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Mami Sasaki): The introduction of AI into government decision-making can enhance transparency and accountability. According to the Wikipedia page on 'Artificial intelligence in government,' AI can be used to further public policy objectives and improve public interaction with the government. It can assist in areas such as emergency services, health, and welfare, as well as through the use of virtual assistants. The use of AI in government can lead to cost savings and reduce the opportunities for corruption. Additionally, there is a growing recognition of the need for regulation and ethics guidelines to ensure responsible deployment of AI in government, as highlighted in the page on 'Regulation of artificial intelligence.' Thus, integrating AI into government decision-making can promote transparency and accountability while leveraging advanced analysis capabilities and prediction models for more objective and efficient policy decisions.\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Wikipedia\",\n",
      "    \"action_input\": \"Transparency in decision-making processes with AI\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Automated decision-making\n",
      "Summary: Automated decision-making (ADM) involves the use of data, machines and algorithms to make decisions in a range of contexts, including public administration, business, health, education, law, employment, transport, media and entertainment, with varying degrees of human oversight or intervention. ADM involves large-scale data from a range of sources, such as databases, text, social media, sensors, images or speech, that is processed using various technologies including computer software, algorithms, machine learning, natural language processing, artificial intelligence, augmented intelligence and robotics. The increasing use of automated decision-making systems (ADMS) across a range of contexts presents many benefits and challenges to human society requiring consideration of the technical, legal, ethical, societal, educational, economic and health consequences.\n",
      "\n",
      "Page: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is also the field of study in computer science that develops and studies intelligent machines. \"AI\" may also refer to the machines themselves.\n",
      "AI technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or creative tools (ChatGPT and AI art), and competing at the highest level in strategic games (such as chess and Go).Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by disappointment and loss of funding, but after 2012, when deep learning surpassed all previous AI techniques, there was a vast increase in funding and interest.\n",
      "The various sub-fields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence (the ability to solve an arbitrary problem) is among the field's long-term goals.\n",
      "To solve these problems, AI researchers have adapted and integrated a wide range of problem-solving techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience and many other fields.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The introduction of AI into government decision-making can enhance transparency and accountability. According to the Wikipedia page on 'Artificial intelligence in government,' AI can be used to further public policy objectives and improve public interaction with the government. It can assist in areas such as emergency services, health, and welfare, as well as through the use of virtual assistants. The use of AI in government can lead to cost savings and reduce the opportunities for corruption. Additionally, there is a growing recognition of the need for regulation and ethics guidelines to ensure responsible deployment of AI in government, as highlighted in the page on 'Regulation of artificial intelligence.' Thus, integrating AI into government decision-making can promote transparency and accountability while leveraging advanced analysis capabilities and prediction models for more objective and efficient policy decisions.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Tomoyuki Ishii): The introduction of AI into government decision-making can enhance transparency and accountability. According to the Wikipedia page on 'Artificial intelligence in government,' AI can be used to further public policy objectives and improve public interaction with the government. It can assist in areas such as emergency services, health, and welfare, as well as through the use of virtual assistants. The use of AI in government can lead to cost savings and reduce the opportunities for corruption. Additionally, there is a growing recognition of the need for regulation and ethics guidelines to ensure responsible deployment of AI in government, as highlighted in the page on 'Regulation of artificial intelligence.' Thus, integrating AI into government decision-making can promote transparency and accountability while leveraging advanced analysis capabilities and prediction models for more objective and efficient policy decisions.\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Wikipedia\",\n",
      "    \"action_input\": \"Artificial intelligence bias\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Algorithmic bias\n",
      "Summary: Algorithmic bias describes systematic and repeatable errors in a computer system that create \"unfair\" outcomes, such as \"privileging\" one category over another in ways different from the intended function of the algorithm.\n",
      "For mapping this to ideas in statistical learning, it is ```extremely important``` to note that the \"bias\" here is typically the ```variance``` in the bias-variance trade off in machine learning. So it is actually the opposite of real machine learning bias. It is variance, the model is over-fitting the data or data generation process. In situations where there was no training data and or no consistent learning, then the \"algorithmic bias\" is simply a measure of deviation according to some score.\n",
      "Bias can emerge from many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm. For example, algorithmic bias has been observed in search engine results and social media platforms. This bias can have impacts ranging from inadvertent privacy violations to reinforcing social biases of race, gender, sexuality, and ethnicity. The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination. This bias has only recently been addressed in legal frameworks, such as the European Union's General Data Protection Regulation (2018) and the proposed Artificial Intelligence Act (2021).\n",
      "As algorithms expand their ability to organize society, politics, institutions, and behavior, sociologists have become concerned with the ways in which unanticipated output and manipulation of data can impact the physical world. Because algorithms are often considered to be neutral and unbiased, they can inaccurately project greater authority than human expertise (in part due to the psychological phenomenon of automation bias), and in some cases, reliance on algorithms can displace human responsibility for their outcomes. Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.\n",
      "Algorithmic bias has been cited in cases ranging from election outcomes to the spread of online hate speech. It has also arisen in criminal justice, healthcare, and hiring, compounding existing racial, socioeconomic, and gender biases. The relative inability of facial recognition technology to accurately identify darker-skinned faces has been linked to multiple wrongful arrests of black men, an issue stemming from imbalanced datasets. Problems in understanding, researching, and discovering algorithmic bias persist due to the proprietary nature of algorithms, which are typically treated as trade secrets. Even when full transparency is provided, the complexity of certain algorithms poses a barrier to understanding their functioning. Furthermore, algorithms may change, or respond to input or output in ways that cannot be anticipated or easily reproduced for analysis. In many cases, even within a single website or application, there is no single \"algorithm\" to examine, but a network of many interrelated programs and data inputs, even between users of the same service.\n",
      "\n",
      "Page: Ethics of artificial intelligence\n",
      "Summary: The ethics of artificial intelligence is the branch of the ethics of technology specific to artificially intelligent systems. It is sometimes divided into a concern with the moral behavior of humans as they design, make, use and treat artificially intelligent systems, and a concern with the behavior of machines, in machine ethics.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Introducing AI into government decision-making processes can indeed bring about potential risks of algorithmic bias. Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one category over another in ways different from the intended function of the algorithm. This bias can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. It has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity (Algorithmic bias, Wikipedia). Therefore, it is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Mami Sasaki): Introducing AI into government decision-making processes can indeed bring about potential risks of algorithmic bias. Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one category over another in ways different from the intended function of the algorithm. This bias can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. It has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity (Algorithmic bias, Wikipedia). Therefore, it is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\n",
      "\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Wikipedia\",\n",
      "    \"action_input\": \"Algorithmic bias\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Algorithmic bias\n",
      "Summary: Algorithmic bias describes systematic and repeatable errors in a computer system that create \"unfair\" outcomes, such as \"privileging\" one category over another in ways different from the intended function of the algorithm.\n",
      "For mapping this to ideas in statistical learning, it is ```extremely important``` to note that the \"bias\" here is typically the ```variance``` in the bias-variance trade off in machine learning. So it is actually the opposite of real machine learning bias. It is variance, the model is over-fitting the data or data generation process. In situations where there was no training data and or no consistent learning, then the \"algorithmic bias\" is simply a measure of deviation according to some score.\n",
      "Bias can emerge from many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm. For example, algorithmic bias has been observed in search engine results and social media platforms. This bias can have impacts ranging from inadvertent privacy violations to reinforcing social biases of race, gender, sexuality, and ethnicity. The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination. This bias has only recently been addressed in legal frameworks, such as the European Union's General Data Protection Regulation (2018) and the proposed Artificial Intelligence Act (2021).\n",
      "As algorithms expand their ability to organize society, politics, institutions, and behavior, sociologists have become concerned with the ways in which unanticipated output and manipulation of data can impact the physical world. Because algorithms are often considered to be neutral and unbiased, they can inaccurately project greater authority than human expertise (in part due to the psychological phenomenon of automation bias), and in some cases, reliance on algorithms can displace human responsibility for their outcomes. Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.\n",
      "Algorithmic bias has been cited in cases ranging from election outcomes to the spread of online hate speech. It has also arisen in criminal justice, healthcare, and hiring, compounding existing racial, socioeconomic, and gender biases. The relative inability of facial recognition technology to accurately identify darker-skinned faces has been linked to multiple wrongful arrests of black men, an issue stemming from imbalanced datasets. Problems in understanding, researching, and discovering algorithmic bias persist due to the proprietary nature of algorithms, which are typically treated as trade secrets. Even when full transparency is provided, the complexity of certain algorithms poses a barrier to understanding their functioning. Furthermore, algorithms may change, or respond to input or output in ways that cannot be anticipated or easily reproduced for analysis. In many cases, even within a single website or application, there is no single \"algorithm\" to examine, but a network of many interrelated programs and data inputs, even between users of the same service.\n",
      "\n",
      "Page: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. It is also the field of study in computer science that develops and studies intelligent machines. \"AI\" may also refer to the machines themselves.\n",
      "AI technology is widely used throughout industry, government and science. Some high-profile applications are: advanced web search engines (e.g., Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes. It can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. Algorithmic bias has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity. It is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Tomoyuki Ishii): Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes. It can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. Algorithmic bias has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity. It is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\n",
      "\n",
      "\n",
      "6\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Artificial intelligence in government\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Artificial intelligence in government\n",
      "Summary: Artificial intelligence (AI) has a range of uses in government. It can be used to further public policy objectives (in areas such as emergency services, health and welfare), as well as assist the public to interact with the government  (through the use of virtual assistants, for example). According to the Harvard Business Review, \"Applications of artificial intelligence to the public sector are broad and growing, with early experiments taking place around the world.\" Hila Mehr from the Ash Center for Democratic Governance and Innovation at Harvard University notes that AI in government is not new, with postal services using machine methods in the late 1990s to recognise handwriting on envelopes to automatically route letters. The use of AI in government comes with significant benefits, including efficiencies resulting in cost savings (for instance by reducing the number of front office staff), and reducing the opportunities for corruption. However, it also carries risks.\n",
      "\n",
      "Page: Generative artificial intelligence\n",
      "Summary: Generative artificial intelligence (also generative AI or GenAI) is artificial intelligence capable of generating text, images, or other media, using generative models. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.In the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.Generative AI has uses across a wide range of industries, including art, writing, script writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.\n",
      "Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models. However, there are also concerns about the potential misuse of generative AI, including cybercrime or creating fake news or deepfakes which can be used to deceive or manipulate people.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes. It can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. Algorithmic bias has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity. It is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Mami Sasaki): Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes. It can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. Algorithmic bias has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity. It is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{ \"action\": \"arxiv\", \"action_input\": \"AI in government decision-making\" }\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mPublished: 2023-10-03\n",
      "Title: Towards Effective Human-AI Decision-Making: The Role of Human Learning in Appropriate Reliance on AI Advice\n",
      "Authors: Max Schemmer, Andrea Bartos, Philipp Spitzer, Patrick Hemmer, Niklas Kühl, Jonas Liebschner, Gerhard Satzger\n",
      "Summary: The true potential of human-AI collaboration lies in exploiting the\n",
      "complementary capabilities of humans and AI to achieve a joint performance\n",
      "superior to that of the individual AI or human, i.e., to achieve complementary\n",
      "team performance (CTP). To realize this complementarity potential, humans need\n",
      "to exercise discretion in following AI 's advice, i.e., appropriately relying\n",
      "on the AI's advice. While previous work has focused on building a mental model\n",
      "of the AI to assess AI recommendations, recent research has shown that the\n",
      "mental model alone cannot explain appropriate reliance. We hypothesize that, in\n",
      "addition to the mental model, human learning is a key mediator of appropriate\n",
      "reliance and, thus, CTP. In this study, we demonstrate the relationship between\n",
      "learning and appropriate reliance in an experiment with 100 participants. This\n",
      "work provides fundamental concepts for analyzing reliance and derives\n",
      "implications for the effective design of human-AI decision-making.\n",
      "\n",
      "Published: 2023-01-31\n",
      "Title: Putting AI Ethics into Practice: The Hourglass Model of Organizational AI Governance\n",
      "Authors: Matti Mäntymäki, Matti Minkkinen, Teemu Birkstedt, Mika Viljanen\n",
      "Summary: The organizational use of artificial intelligence (AI) has rapidly spread\n",
      "across various sectors. Alongside the awareness of the benefits brought by AI,\n",
      "there is a growing consensus on the necessity of tackling the risks and\n",
      "potential harms, such as bias and discrimination, brought about by advanced AI\n",
      "technologies. A multitude of AI ethics principles have been proposed to tackle\n",
      "these risks, but the outlines of organizational processes and practices for\n",
      "ensuring socially responsible AI development are in a nascent state. To address\n",
      "the paucity of comprehensive governance models, we present an AI governance\n",
      "framework, the hourglass model of organizational AI governance, which targets\n",
      "organizations that develop and use AI systems. The framework is designed to\n",
      "help organizations deploying AI systems translate ethical AI principles into\n",
      "practice and align their AI systems and processes with the forthcoming European\n",
      "AI Act. The hourglass framework includes governance requirements at the\n",
      "environmental, organizational, and AI system levels. At the AI system level, we\n",
      "connect governance requirements to AI system life cycles to ensure governance\n",
      "throughout the system's life span. The governance model highlights the systemic\n",
      "nature of AI governance and opens new research avenues into its practical\n",
      "implementation, the mechanisms that connect different AI governance layers, and\n",
      "the dynamics between the AI governance actors. The model also offers a starting\n",
      "point for organizational decision-makers to consider the governance components\n",
      "needed to ensure social acceptability, mitigate risks, and realize the\n",
      "potential of AI.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The introduction of AI into government decision-making processes can indeed bring about potential risks of algorithmic bias. Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one category over another in ways different from the intended function of the algorithm. This bias can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. It has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity. Therefore, it is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Tomoyuki Ishii): The introduction of AI into government decision-making processes can indeed bring about potential risks of algorithmic bias. Algorithmic bias refers to systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one category over another in ways different from the intended function of the algorithm. This bias can emerge from various factors, including the design of the algorithm, the way data is coded, collected, selected, or used to train the algorithm. It has been observed in search engine results and social media platforms, leading to inadvertent privacy violations and reinforcing social biases based on race, gender, sexuality, and ethnicity. Therefore, it is crucial to exercise caution when integrating AI into decision-making processes and take necessary steps to address and mitigate algorithmic bias.\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{ \"action\": \"Wikipedia\", \"action_input\": \"Artificial intelligence in government\" }\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Artificial intelligence in government\n",
      "Summary: Artificial intelligence (AI) has a range of uses in government. It can be used to further public policy objectives (in areas such as emergency services, health and welfare), as well as assist the public to interact with the government  (through the use of virtual assistants, for example). According to the Harvard Business Review, \"Applications of artificial intelligence to the public sector are broad and growing, with early experiments taking place around the world.\" Hila Mehr from the Ash Center for Democratic Governance and Innovation at Harvard University notes that AI in government is not new, with postal services using machine methods in the late 1990s to recognise handwriting on envelopes to automatically route letters. The use of AI in government comes with significant benefits, including efficiencies resulting in cost savings (for instance by reducing the number of front office staff), and reducing the opportunities for corruption. However, it also carries risks.\n",
      "\n",
      "Page: Generative artificial intelligence\n",
      "Summary: Generative artificial intelligence (also generative AI or GenAI) is artificial intelligence capable of generating text, images, or other media, using generative models. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.In the early 2020s, advances in transformer-based deep neural networks enabled a number of generative AI systems notable for accepting natural language prompts as input. These include large language model chatbots such as ChatGPT, Bing Chat, Bard, and LLaMA, and text-to-image artificial intelligence art systems such as Stable Diffusion, Midjourney, and DALL-E.Generative AI has uses across a wide range of industries, including art, writing, script writing, software development, product design, healthcare, finance, gaming, marketing, and fashion.\n",
      "Investment in generative AI surged during the early 2020s, with large companies such as Microsoft, Google, and Baidu as well as numerous smaller firms developing generative AI models. However, there are also concerns about the potential misuse of generative AI, including cybercrime or creating fake news or deepfakes which can be used to deceive or manipulate people.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The use of AI in government can bring significant benefits in terms of efficiency, cost savings, and reducing opportunities for corruption. It can further public policy objectives and improve public interaction with the government. However, it also carries risks, such as algorithmic bias, which needs to be addressed and mitigated through careful integration and necessary steps. The potential benefits and risks of AI in government decision-making should be considered and balanced, with a focus on promoting transparency and accountability while leveraging advanced analysis capabilities for more objective and efficient policy decisions.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Mami Sasaki): The use of AI in government can bring significant benefits in terms of efficiency, cost savings, and reducing opportunities for corruption. It can further public policy objectives and improve public interaction with the government. However, it also carries risks, such as algorithmic bias, which needs to be addressed and mitigated through careful integration and necessary steps. The potential benefits and risks of AI in government decision-making should be considered and balanced, with a focus on promoting transparency and accountability while leveraging advanced analysis capabilities for more objective and efficient policy decisions.\n",
      "\n",
      "\n",
      "9\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"duckduckgo_search\",\n",
      "    \"action_input\": \"Benefits of AI in government decision-making\"\n",
      "}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAI can bring real benefits to consumers—for example, by making products better, cheaper, and more widely available. But AI also raises the risk of injuring, misleading, or otherwise harming ... The public sector deals with large amounts of data, so increasing efficiency is key., AI and automation can help increase processing speed, minimize costs, and provide services to the public faster. This article discusses major use cases of AI for governments, including: Traffic flow analysis Improving healthcare services \"AI can help in getting an informational picture about what is going on but making complex decisions about how, when and why … is not an AI decision,\" Allen said. Explore more on these ... Correction policy Artificial intelligence, also known as AI, has become an integral part of our lives. From Siri answering our questions to Netflix recommending shows, AI is everywhere. But have you ever stopped to think about its impact on government and policymaking? That's exactly what we're going to explore in this post. Numerous pilot projects in recent years have proven the value of artificial intelligence (AI) in government and paved the way for wider adoption. At the same time, state and local agencies are ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The use of AI in government can bring significant benefits in terms of efficiency, cost savings, and reducing opportunities for corruption. It can further public policy objectives and improve public interaction with the government. However, it also carries risks, such as algorithmic bias, which needs to be addressed and mitigated through careful integration and necessary steps. The potential benefits and risks of AI in government decision-making should be considered and balanced, with a focus on promoting transparency and accountability while leveraging advanced analysis capabilities for more objective and efficient policy decisions.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "(Tomoyuki Ishii): The use of AI in government can bring significant benefits in terms of efficiency, cost savings, and reducing opportunities for corruption. It can further public policy objectives and improve public interaction with the government. However, it also carries risks, such as algorithmic bias, which needs to be addressed and mitigated through careful integration and necessary steps. The potential benefits and risks of AI in government decision-making should be considered and balanced, with a focus on promoting transparency and accountability while leveraging advanced analysis capabilities for more objective and efficient policy decisions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from src.agents import DialogueAgentWithTools\n",
    "\n",
    "\n",
    "def select_next_speaker(step: int, agents: List[DialogueAgentWithTools]) -> int:\n",
    "    idx = (step) % len(agents)\n",
    "    return idx\n",
    "\n",
    "\n",
    "specified_topic = world.concretize_topic(word_limit=100)\n",
    "\n",
    "max_iters = 10\n",
    "\n",
    "simulator = DialogueSimulator(\n",
    "    agents=world.agents, selection_function=SpeakerSelector.select_in_order\n",
    ")\n",
    "simulator.reset()\n",
    "simulator.inject(\"Moderator\", specified_topic)\n",
    "print(f\"(Moderator): {specified_topic}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "import time\n",
    "\n",
    "for step in range(max_iters):\n",
    "    print(step)\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
